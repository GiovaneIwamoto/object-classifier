{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**CLASSIFIER**"
      ],
      "metadata": {
        "id": "7h72kzqntADH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###CUSTOM ARCHITECTURE"
      ],
      "metadata": {
        "id": "RkDNH2SJLOXN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradient-descent-the-ultimate-optimizer"
      ],
      "metadata": {
        "id": "IlvtdHLpeuVp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40454607-d5ca-4d18-b7c7-5e321322fb60"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gradient-descent-the-ultimate-optimizer in /usr/local/lib/python3.10/dist-packages (1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "aDTlpHdeYDHK"
      },
      "outputs": [],
      "source": [
        "# LIBRARIES\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import classification_report\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "id": "SIq-a8RaJDfD"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TRANSFORM\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])"
      ],
      "metadata": {
        "id": "dOuBMTvzVJJ5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CIFAR-100\n",
        "train_dataset = datasets.CIFAR100(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.CIFAR100(root='./data', train=False, download=True, transform=transform)"
      ],
      "metadata": {
        "id": "SOeNl-_kJWK8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb78690c-c34d-4716-cc7b-5be8a02a0d70"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data/cifar-100-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 169001437/169001437 [00:02<00:00, 78365217.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-100-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DATALOADER\n",
        "batch_size = 128\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "JpAdY_1DJsl1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8-CONV LAYER ARCHITECTURE\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv_layers = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "        self.fc_layers = nn.Sequential(\n",
        "            nn.Linear(128 * 4 * 4, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 100)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_layers(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc_layers(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "CkZ6gw40LDKE"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MODEL INSTANCE\n",
        "model = CNN().to(device)\n"
      ],
      "metadata": {
        "id": "m5TJiw3TNMaL"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LOSS / OPTMIMIZER\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "2yFu6Qp8NN5j"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MODEL\n",
        "num_epochs = 5\n",
        "train_losses = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Loss Update\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        if batch_idx % 100 == 99:\n",
        "            print(f\"Epoch [{epoch+1}/{num_epochs}], Batch [{batch_idx+1}/{len(train_loader)}], Loss: {running_loss/100:.4f}\")\n",
        "            running_loss = 0.0\n",
        "    \n",
        "    train_losses.append(running_loss / len(train_loader))\n",
        "\n",
        "print(\"Completed training!\")"
      ],
      "metadata": {
        "id": "GTALmf7kNekb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "022fb2df-c7b6-4b96-a171-f2b4c795e88d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Batch [100/391], Loss: 4.4538\n",
            "Epoch [1/5], Batch [200/391], Loss: 4.2648\n",
            "Epoch [1/5], Batch [300/391], Loss: 4.0624\n",
            "Epoch [2/5], Batch [100/391], Loss: 3.8570\n",
            "Epoch [2/5], Batch [200/391], Loss: 3.7634\n",
            "Epoch [2/5], Batch [300/391], Loss: 3.6423\n",
            "Epoch [3/5], Batch [100/391], Loss: 3.4576\n",
            "Epoch [3/5], Batch [200/391], Loss: 3.3836\n",
            "Epoch [3/5], Batch [300/391], Loss: 3.3166\n",
            "Epoch [4/5], Batch [100/391], Loss: 3.1696\n",
            "Epoch [4/5], Batch [200/391], Loss: 3.1082\n",
            "Epoch [4/5], Batch [300/391], Loss: 3.0326\n",
            "Epoch [5/5], Batch [100/391], Loss: 2.9009\n",
            "Epoch [5/5], Batch [200/391], Loss: 2.8596\n",
            "Epoch [5/5], Batch [300/391], Loss: 2.8113\n",
            "Completed training!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "total_correct = 0\n",
        "total_samples = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        total_samples += labels.size(0)\n",
        "        total_correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = 100 * total_correct / total_samples\n",
        "print(f\"CUSTOM_MODEL's accuracy on the test data: {accuracy:.2f}%\")\n",
        "\n",
        "# Plot the training loss curve\n",
        "plt.plot(range(num_epochs), train_losses)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Training Loss')\n",
        "plt.title('Training Loss Curve')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "65WkRZK72Jsx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "outputId": "cf06799c-f40e-4c5c-acc3-1e5034e1f83c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUSTOM_MODEL's accuracy on the test data: 28.64%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SAVE PARAMS\n",
        "torch.save(model.state_dict(), 'custom_model.pth')\n"
      ],
      "metadata": {
        "id": "zdDL2-TmQNXa"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FINETUNNING - CUSTOM_MODEL"
      ],
      "metadata": {
        "id": "3FFao0lXr8o5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LIBRARIES\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.transforms import transforms\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "nnQq3ucZOPku"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TRANSFORM\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "test_file_paths =  '/content/drive/MyDrive/dataset/test'\n",
        "train_file_paths = '/content/drive/MyDrive/dataset/training'\n",
        "val_file_paths = '/content/drive/MyDrive/dataset/validation'\n",
        "\n",
        "test_data = ImageFolder(root=test_file_paths, transform=transform)\n",
        "train_data = ImageFolder(root=train_file_paths, transform=transform)\n",
        "valid_data = ImageFolder(root=val_file_paths, transform=transform)\n",
        "\n",
        "# Create DataLoaders for training and validation\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=32, shuffle=True)\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "EWZzLPc8unkq"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MODEL\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = CNN()"
      ],
      "metadata": {
        "id": "_fvpQGbTOcDW"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('/content/custom_model.pth'))\n"
      ],
      "metadata": {
        "id": "aWVTLHTXKo-p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc349b39-d5f6-4159-b092-cc9ce057c1e3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# REPLACE LAST LAYER \n",
        "model.fc_layers = nn.Sequential(\n",
        "    nn.Linear(128 * 4 * 4, 512),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(512, 256),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(256, 5)\n",
        ")\n",
        "model.to(device)\n"
      ],
      "metadata": {
        "id": "OysnB8HwsSvW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e84c61c-49e8-4b17-b932-f0a87df535f7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN(\n",
              "  (conv_layers): Sequential(\n",
              "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU()\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU()\n",
              "    (7): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): ReLU()\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU()\n",
              "    (12): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU()\n",
              "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (fc_layers): Sequential(\n",
              "    (0): Linear(in_features=2048, out_features=512, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=256, out_features=5, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LOSS / OPTMIMIZER\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
      ],
      "metadata": {
        "id": "b5Ms8HwSsiYS"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FINE-TUNNING\n",
        "num_epochs = 5\n",
        "\n",
        "train_losses = []\n",
        "valid_losses = []\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    valid_loss = 0.0\n",
        "\n",
        "    # Training\n",
        "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for images, labels in valid_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            valid_loss += loss.item()\n",
        "\n",
        "    # Calculate average losses\n",
        "    train_loss /= len(train_loader)\n",
        "    valid_loss /= len(valid_loader)\n",
        "\n",
        "    # Store losses\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "\n",
        "    # Print losses\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {train_loss:.4f}, Validation Loss: {valid_loss:.4f}\")\n",
        "\n",
        "    # Check if validation loss improved\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        # Save the model\n",
        "\n",
        "print(\"Completed fine-tuning!\")"
      ],
      "metadata": {
        "id": "zy-zvPLAtgGW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LOSS / MATRIX\n",
        "model.eval()\n",
        "total_correct = 0\n",
        "total_samples = 0\n",
        "predictions = []\n",
        "test_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        total_samples += labels.size(0)\n",
        "        total_correct += (predicted == labels).sum().item()\n",
        "        predictions.extend(predicted.tolist())\n",
        "        test_labels.extend(labels.tolist())\n",
        "\n",
        "accuracy = 100 * total_correct / total_samples\n",
        "print(f\"CUSTOM_MODEL's accuracy on the test data: {accuracy:.2f}%\")\n",
        "\n",
        "# Plot the training and validation loss curves\n",
        "plt.plot(range(num_epochs), train_losses, label='Training Loss')\n",
        "plt.plot(range(num_epochs), valid_losses, label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss Curves')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Create the confusion matrix\n",
        "predictions = np.array(predictions)\n",
        "test_labels = np.array(test_labels)\n",
        "cm = confusion_matrix(test_labels, predictions)\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Compute precision, recall, and F1 scores\n",
        "predictions = np.array(predictions)\n",
        "test_labels = np.array(test_labels)\n",
        "report = classification_report(test_loader.dataset.targets, predictions)\n",
        "print(report)"
      ],
      "metadata": {
        "id": "z60bvGm31dGn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'custom_model_fined.pth')\n"
      ],
      "metadata": {
        "id": "qsLwppfDEpvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FINETUNNING - MOBILENET_V3_SMALL "
      ],
      "metadata": {
        "id": "OPL7-dRHEyqc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LOAD ARCHITECTURE\n",
        "from torchvision.models import mobilenet_v3_small\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "xP60lcUkFLnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TRANSFORM\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "test_file_paths =  '/content/drive/MyDrive/dataset/test'\n",
        "train_file_paths = '/content/drive/MyDrive/dataset/training'\n",
        "val_file_paths = '/content/drive/MyDrive/dataset/validation'\n",
        "\n",
        "test_data = ImageFolder(root=test_file_paths, transform=transform)\n",
        "train_data = ImageFolder(root=train_file_paths, transform=transform)\n",
        "valid_data = ImageFolder(root=val_file_paths, transform=transform)\n",
        "\n",
        "# Create DataLoaders for training and validation\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=32, shuffle=True)\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "l9Bx1iMwaxSo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MODEL\n",
        "model = mobilenet_v3_small(pretrained=True)"
      ],
      "metadata": {
        "id": "nYQ9wtn6a1uY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 5\n",
        "model.classifier[-1] = nn.Linear(model.classifier[-1].in_features, len(train_data.classes))"
      ],
      "metadata": {
        "id": "iTT62zTpFSJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n"
      ],
      "metadata": {
        "id": "-bu4h16lFUcZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "iNLPEXxyb7_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FINETUNNING\n",
        "num_epochs = 10\n",
        "\n",
        "train_losses = []\n",
        "valid_losses = []\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        if batch_idx % 100 == 99:\n",
        "            print(f\"Epoch [{epoch+1}/{num_epochs}], Batch [{batch_idx+1}/{len(train_loader)}], Loss: {running_loss/100:.4f}\")\n",
        "            running_loss = 0.0\n",
        "    \n",
        "    # Calculate average training loss\n",
        "    avg_train_loss = running_loss / len(train_loader)\n",
        "    train_losses.append(avg_train_loss)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    valid_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in valid_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            valid_loss += loss.item()\n",
        "\n",
        "    # Calculate average validation loss\n",
        "    avg_valid_loss = valid_loss / len(valid_loader)\n",
        "    valid_losses.append(avg_valid_loss)\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {avg_train_loss:.4f}, Validation Loss: {avg_valid_loss:.4f}\")\n",
        "\n",
        "    # Check if validation loss improved\n",
        "    if avg_valid_loss < best_valid_loss:\n",
        "        best_valid_loss = avg_valid_loss\n",
        "        # Save the model\n",
        "\n",
        "print(\"Completed fine-tuning!\")"
      ],
      "metadata": {
        "id": "QkMnq9kSFn6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LOSS / MATRIX\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "model.eval()\n",
        "total_correct = 0\n",
        "total_samples = 0\n",
        "predictions = []\n",
        "test_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        total_samples += labels.size(0)\n",
        "        total_correct += (predicted == labels).sum().item()\n",
        "        predictions.extend(predicted.tolist())\n",
        "        test_labels.extend(labels.tolist())\n",
        "\n",
        "accuracy = 100 * total_correct / total_samples\n",
        "print(f\"MOBILENET_V3_SMALL's accuracy on the test data: {accuracy:.2f}%\")\n",
        "\n",
        "# Plot the training and validation loss curves\n",
        "plt.plot(range(num_epochs), train_losses, label='Training Loss')\n",
        "plt.plot(range(num_epochs), valid_losses, label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss Curves')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Create the confusion matrix\n",
        "predictions = np.array(predictions)\n",
        "test_labels = np.array(test_labels)\n",
        "cm = confusion_matrix(test_labels, predictions)\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Compute precision, recall, and F1 scores\n",
        "predictions = np.array(predictions)\n",
        "test_labels = np.array(test_labels)\n",
        "report = classification_report(test_loader.dataset.targets, predictions)\n",
        "print(report)"
      ],
      "metadata": {
        "id": "XkOg6dml6KcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'mobilenet_v3_small.pth')\n"
      ],
      "metadata": {
        "id": "V-MK3tu4J9-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FINETUNNING - SHUFFLENET_V2_X0_5\n"
      ],
      "metadata": {
        "id": "WppAI5FSPCVn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LOAD ARCHITECTURE\n",
        "from torchvision.models import shufflenet_v2_x0_5\n",
        "model = shufflenet_v2_x0_5(pretrained=True)"
      ],
      "metadata": {
        "id": "25cfIAXWPOGr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 5\n",
        "model.fc = nn.Linear(model.fc.in_features, num_classes)\n"
      ],
      "metadata": {
        "id": "gd32cHvJPXgs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
      ],
      "metadata": {
        "id": "CIJErsmqPbn0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FINETUNNING\n",
        "num_epochs = 20\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Loss Update\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        if batch_idx % 100 == 99:\n",
        "            print(f\"Epoch [{epoch+1}/{num_epochs}], Batch [{batch_idx+1}/{len(train_loader)}], Loss: {running_loss/100:.4f}\")\n",
        "            running_loss = 0.0\n",
        "    \n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
        "\n",
        "print(\"Completed fine-tuning!\")"
      ],
      "metadata": {
        "id": "de5R5WBPPeys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LOSS / MATRIX\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "model.eval()\n",
        "total_correct = 0\n",
        "total_samples = 0\n",
        "predictions = []\n",
        "test_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        total_samples += labels.size(0)\n",
        "        total_correct += (predicted == labels).sum().item()\n",
        "        predictions.extend(predicted.tolist())\n",
        "        test_labels.extend(labels.tolist())\n",
        "\n",
        "accuracy = 100 * total_correct / total_samples\n",
        "print(f\"SHUFFLENET_V2_X0_5's accuracy on the test data: {accuracy:.2f}%\")\n",
        "\n",
        "# Plot the training and validation loss curves\n",
        "plt.plot(range(num_epochs), train_losses, label='Training Loss')\n",
        "plt.plot(range(num_epochs), valid_losses, label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss Curves')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Create the confusion matrix\n",
        "predictions = np.array(predictions)\n",
        "test_labels = np.array(test_labels)\n",
        "cm = confusion_matrix(test_labels, predictions)\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Compute precision, recall, and F1 scores\n",
        "predictions = np.array(predictions)\n",
        "test_labels = np.array(test_labels)\n",
        "report = classification_report(test_loader.dataset.targets, predictions)\n",
        "print(report)"
      ],
      "metadata": {
        "id": "ANMCHYyg-8mz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'shufflenet_v2_x0_5.pth')\n"
      ],
      "metadata": {
        "id": "dSJF83QpPhGc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FINETUNNING - SQUEEZENET1_0\n"
      ],
      "metadata": {
        "id": "WzycgiPmT4G7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models import squeezenet1_0\n",
        "model = squeezenet1_0(pretrained=True)"
      ],
      "metadata": {
        "id": "E2ayN-eyUC2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 5\n",
        "model.classifier._modules['1'] = nn.Conv2d(512, num_classes, kernel_size=(1, 1))\n"
      ],
      "metadata": {
        "id": "LkzXlkn4UTa5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
      ],
      "metadata": {
        "id": "q6zs7eSsUdjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FINETUNNING\n",
        "num_epochs = 20\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Loss Update\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        if batch_idx % 100 == 99:\n",
        "            print(f\"Epoch [{epoch+1}/{num_epochs}], Batch [{batch_idx+1}/{len(train_loader)}], Loss: {running_loss/100:.4f}\")\n",
        "            running_loss = 0.0\n",
        "    \n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
        "\n",
        "print(\"Completed fine-tuning!\")"
      ],
      "metadata": {
        "id": "B2LVA1KRUgCG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LOSS / MATRIX\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "model.eval()\n",
        "total_correct = 0\n",
        "total_samples = 0\n",
        "predictions = []\n",
        "test_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        total_samples += labels.size(0)\n",
        "        total_correct += (predicted == labels).sum().item()\n",
        "        predictions.extend(predicted.tolist())\n",
        "        test_labels.extend(labels.tolist())\n",
        "\n",
        "accuracy = 100 * total_correct / total_samples\n",
        "print(f\"SQUEEZENET1_0's accuracy on the test data: {accuracy:.2f}%\")\n",
        "\n",
        "# Plot the training and validation loss curves\n",
        "plt.plot(range(num_epochs), train_losses, label='Training Loss')\n",
        "plt.plot(range(num_epochs), valid_losses, label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss Curves')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Create the confusion matrix\n",
        "predictions = np.array(predictions)\n",
        "test_labels = np.array(test_labels)\n",
        "cm = confusion_matrix(test_labels, predictions)\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Compute precision, recall, and F1 scores\n",
        "predictions = np.array(predictions)\n",
        "test_labels = np.array(test_labels)\n",
        "report = classification_report(test_loader.dataset.targets, predictions)\n",
        "print(report)"
      ],
      "metadata": {
        "id": "iqhK-3gc_LAP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'squeezenet1_0.pth')\n"
      ],
      "metadata": {
        "id": "-SJOBUnKU0UR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}